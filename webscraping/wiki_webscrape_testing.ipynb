{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook to create and test functions for webscraping\n",
    "\n",
    "##### Using [Wikipedia to get current list of S&P 500 companies](https://en.wikipedia.org/wiki/List_of_S%26P_500_companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content():\n",
    "    wiki_url = r'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "    payload = requests.get(wiki_url)\n",
    "    soup = BeautifulSoup(payload.content)\n",
    "    return(soup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = get_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_constituents(soup, name):\n",
    "    table = soup.find('table', id=name)\n",
    "    header = []\n",
    "    rows = []\n",
    "    for i, row in enumerate(table.find_all('tr')):\n",
    "        if i == 0:\n",
    "            header = [el.text.strip() for el in row.find_all('th')]\n",
    "        else:\n",
    "            rows.append([el.text.strip() for el in row.find_all('td')])\n",
    "    \n",
    "    df = pd.DataFrame(rows, columns = header)\n",
    "    return(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constituents = get_constituents(s, 'constituents')\n",
    "base = constituents[['Symbol', 'Date added']].rename(columns ={ 'Symbol':'ticker', 'Date added':'date_added'}).sort_values(by = 'ticker').reset_index(drop = True)\n",
    "base['date_added'] = pd.to_datetime(base['date_added'])\n",
    "base['currently_listed'] = True\n",
    "base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "change_html = s.find('table', id='changes')\n",
    "for i, row in enumerate(change_html.find_all('tr')):\n",
    "    if i > 1:\n",
    "        rows.append([el.text.strip() for el in row.find_all('td')])\n",
    "        \n",
    "df = pd.DataFrame(rows, columns = ['Date', 'ADD_Symbol', 'ADD_Security', 'RMV_Symbol', 'RMV_Security', 'Reason'])       \n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df = df.replace('', None)\n",
    "\n",
    "#Get Most recent add dates per ticker\n",
    "add_dates = df.loc[df['ADD_Symbol'].isnull() == False][['Date', 'ADD_Symbol']].\\\n",
    "    groupby('ADD_Symbol').agg({'Date':'max'}).reset_index().\\\n",
    "    rename(columns = {'ADD_Symbol':'ticker', 'Date':'date_added'})\n",
    "#Get Most recent remove dates per ticker\n",
    "rmv_dates = df.loc[df['RMV_Symbol'].isnull() == False][['Date', 'RMV_Symbol']].\\\n",
    "    groupby('RMV_Symbol').agg({'Date':'max'}).reset_index().\\\n",
    "    rename(columns = {'RMV_Symbol':'ticker', 'Date':'date_removed'})\n",
    "\n",
    "all_tickers = add_dates.merge(rmv_dates, on = 'ticker', how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_total = base.merge(all_tickers, on = ['ticker', 'date_added'], how = 'outer')\n",
    "tickers_total['currently_listed'] = tickers_total['currently_listed'].fillna(False)\n",
    "#Classify anything without a date added as 1957-01-01\n",
    "tickers_total['date_added'] = [pd.to_datetime('1957-01-01') if pd.isnull(d) == True else d for d in tickers_total['date_added']]\n",
    "\n",
    "dups = list(tickers_total.groupby('ticker').size().loc[lambda x: x > 1].index)\n",
    "no_dups = tickers_total.loc[~tickers_total['ticker'].isin(dups)].sort_values(by = ['ticker', 'date_added'])\n",
    "fix_dups = tickers_total.loc[tickers_total['ticker'].isin(dups)].sort_values(by = ['ticker', 'date_added'])\n",
    "fixed_dups = fix_dups.groupby('ticker').agg({'date_added':'max', 'currently_listed':'max'}).reset_index()\n",
    "fixed_dups['date_removed'] = pd.NaT\n",
    "order = ['ticker', 'date_added', 'date_removed', 'currently_listed']\n",
    "\n",
    "fixed_dups = fixed_dups[order]\n",
    "no_dups = no_dups[order]\n",
    "\n",
    "tickers_total = pd.concat([fixed_dups, no_dups], ignore_index = True).sort_values(by = ['date_added', 'ticker']).reset_index(drop = True)\n",
    "\n",
    "\n",
    "#Create an int ticker_id that will be used as a primary key for tickers\n",
    "tickers_total['ticker_id'] = [i + 10000 for i in tickers_total.index]\n",
    "\n",
    "col_order = [\n",
    "    'ticker_id', 'ticker', 'date_added', 'date_removed', 'currently_listed'\n",
    "]\n",
    "tickers_total = tickers_total[col_order]\n",
    "\n",
    "tickers_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to db\n",
    "conn = os.getenv('STOCK_DB_CONN')\n",
    "engine = create_engine(conn)\n",
    "tickers_total.to_sql(name = 's_and_p_500_history', con = engine, schema = 'NASDAQ', if_exists= 'replace', index = False, method = 'multi')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "post-y2k-stock-performance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
