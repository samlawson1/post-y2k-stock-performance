{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### S&P 500 Historical Listings are sourced from [this](https://github.com/fja05680/sp500) gitub repository\n",
    "> S&P 500 Historical Components & Changes(12-30-2023).csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder = 'source-data'\n",
    "source_file = r'S&P 500 Historical Components & Changes(12-30-2023).csv'\n",
    "read_string = os.path.join(source_folder, source_file)\n",
    "historical_data = pd.read_csv(read_string)\n",
    "\n",
    "#Convert date to datetime dtype\n",
    "historical_data['date'] = pd.to_datetime(historical_data['date'])\n",
    "\n",
    "#For the analysis we only want to look at stocks after the year 2000\n",
    "post_y2k = historical_data.loc[historical_data['date'].dt.year >= 2000].reset_index(drop = True)\n",
    "print(post_y2k['date'].min(), post_y2k['date'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format all stock tickers that have been in the S&P 500 from the start of 2000 until the end of 2023 into a clean dataframe\n",
    "\n",
    "- ticker: stock ticker symbol\n",
    "- start_date: date stock was included in S&P 500\n",
    "    - If stock was already in S&P 500 at the start of 2000, then it's start date = 2000-01-03 (Monday)\n",
    "- end_date: date stock was delisted from S&P 500\n",
    "    - If stock was still listed in S&P 500 as of 2023-12-31 then end_date = 2023-12-31\n",
    "- type: S (stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Format data so we can get min and max dates for each ticker - needed for screenscraping\n",
    "post_y2k_format_concat = []\n",
    "for i in post_y2k.index:\n",
    "    date = post_y2k.iloc[i]['date']\n",
    "    ticker_string = post_y2k.iloc[i]['tickers']\n",
    "    ticker_list = ticker_string.split(',')\n",
    "    df = pd.DataFrame(ticker_list, columns = ['ticker'])\n",
    "    df.insert(0, 'date', date)\n",
    "    post_y2k_format_concat.append(df)\n",
    "\n",
    "formatted_df = pd.concat(post_y2k_format_concat, ignore_index = True)\n",
    "formatted_df['date'] = pd.to_datetime(formatted_df['date'])\n",
    "\n",
    "#Get min and max dates for each ticker\n",
    "s_and_p_stocks = formatted_df.groupby(['ticker']).agg({'date':['min', 'max']}).reset_index()\n",
    "s_and_p_stocks.columns = ['ticker', 'start_date', 'end_date']\n",
    "#format end dates to go to end of 2023 where necessary (end_date == end of data range)\n",
    "end_dates = s_and_p_stocks['end_date']\n",
    "s_and_p_stocks['end_date'] = [pd.to_datetime('2023-12-31') if d == pd.Timestamp('2023-10-18') else d for d in end_dates]\n",
    "#Classify all of these as stocks\n",
    "s_and_p_stocks['type'] = 'S'\n",
    "s_and_p_stocks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I want to include some popular ETF's to compare against in the analysis\n",
    "\n",
    "NOTE: Start Dates sourced from [yahoo finance historical data](https://finance.yahoo.com/)\n",
    "\n",
    "- SPY: SPDR S&P 500 ETF Trust for S&P 500 (aka \"The Market\") - Start Date: 2000-01-03\n",
    "- QQQ: Invesco QQQ Trust ETF for Nasdaq 100 - Start Date: 2009-01-02\n",
    "- IWM: iShares Russell 2000 ETF that includes mid-cap stocks - Start Date: 2000-05-26\n",
    "- GLD: SPDR Gold Shares ETF - Start Date: 2008-01-02\n",
    "- VTI: Vanguard Total Stock Market Index Fund ETF Shares - Start Date: 2008-01-02\n",
    "- BND: Vanguard Total Bond Market Index Fund - Start Date: 2008-01-02\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etf_dict = {\n",
    "    'SPY':{'start_date':'2000-01-03', 'end_date':'2023-12-31', 'type':'E'},\n",
    "    'QQQ':{'start_date':'2009-01-02', 'end_date':'2023-12-31', 'type':'E'},\n",
    "    'IWM':{'start_date':'2000-05-26', 'end_date':'2023-12-31', 'type':'E'},\n",
    "    'GLD':{'start_date':'2008-01-02', 'end_date':'2023-12-31', 'type':'E'},\n",
    "    'VTI':{'start_date':'2008-01-02', 'end_date':'2023-12-31', 'type':'E'},\n",
    "    'BND':{'start_date':'2008-01-02', 'end_date':'2023-12-31', 'type':'E'}\n",
    "}\n",
    "\n",
    "popular_etf = pd.DataFrame.from_dict(etf_dict, orient = 'index').reset_index().rename(columns = {'index':'ticker'})\n",
    "popular_etf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine dataframes into one dataset and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define output folder and filename to send data to\n",
    "output_folder = 'data'\n",
    "if not os.path.exists(output_folder):\n",
    "    os.mkdir(output_folder)\n",
    "\n",
    "output_filename = 'post_Y2K_tickers_for_webscraping.csv'\n",
    "\n",
    "output_path = os.path.join(output_folder, output_filename)\n",
    "\n",
    "#Concat stock and etf datframes into one\n",
    "all_data = pd.concat([s_and_p_stocks, popular_etf], ignore_index= True)\n",
    "all_data.to_csv(output_path, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "post-y2k-stock-performance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
